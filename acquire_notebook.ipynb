{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6431b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b506e7d",
   "metadata": {},
   "source": [
    "# Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f87607",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://web-scraping-demo.zgulde.net/people'\n",
    "response = get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae1885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cb940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = soup.select('div.person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03880c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = people[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f92ed8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {}\n",
    "dct['name'] = person.find('h2').text\n",
    "dct['quote'] = person.find('p').text\n",
    "dct['email'] = person.select('div')[0].select('p')[0].text\n",
    "dct['phone'] = person.select('div')[0].select('p')[1].text\n",
    "dct['address'] = person.select('div')[1].select('p')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d329352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_person(person):\n",
    "    dct = {}\n",
    "    dct['first_name'] = person.select_one('.name').text.split()[0].strip()\n",
    "    dct['last_name'] = person.select_one('.name').text.split()[1].strip()\n",
    "    dct['quote'] = person.select_one('.quote').text.strip()\n",
    "    dct['email'] = person.select_one('.email').text.strip()\n",
    "    dct['phone'] = person.select_one('.phone').text.strip()\n",
    "    dct['address'] = person.select_one('.address').text.strip()\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd107e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>quote</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>address</th>\n",
       "      <th>street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Erika</td>\n",
       "      <td>Singh</td>\n",
       "      <td>\"Expanded upward-trending migration\"</td>\n",
       "      <td>heather10@sanford-tyler.com</td>\n",
       "      <td>(720)024-8715</td>\n",
       "      <td>86428 Carpenter Hills \\n                West A...</td>\n",
       "      <td>86428 Carpenter Hills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David</td>\n",
       "      <td>Hill</td>\n",
       "      <td>\"Future-proofed coherent access\"</td>\n",
       "      <td>beckmaureen@yahoo.com</td>\n",
       "      <td>+1-335-855-9267</td>\n",
       "      <td>853 Barrett Passage \\n                Victoria...</td>\n",
       "      <td>853 Barrett Passage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brittany</td>\n",
       "      <td>Robertson</td>\n",
       "      <td>\"Networked fresh-thinking contingency\"</td>\n",
       "      <td>curtisdennis@gmail.com</td>\n",
       "      <td>(278)228-4260x73351</td>\n",
       "      <td>396 Jennifer Trail \\n                West Mich...</td>\n",
       "      <td>396 Jennifer Trail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Victoria</td>\n",
       "      <td>Jacobs</td>\n",
       "      <td>\"Stand-alone maximized intranet\"</td>\n",
       "      <td>smithrobert@reyes-gonzalez.org</td>\n",
       "      <td>+1-234-910-4214x821</td>\n",
       "      <td>2374 Nicole Ramp \\n                Jonathanfur...</td>\n",
       "      <td>2374 Nicole Ramp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Christine</td>\n",
       "      <td>Davenport</td>\n",
       "      <td>\"Pre-emptive needs-based core\"</td>\n",
       "      <td>tina36@hotmail.com</td>\n",
       "      <td>186-423-9531x65330</td>\n",
       "      <td>3107 Brian Estates Suite 508 \\n               ...</td>\n",
       "      <td>3107 Brian Estates Suite 508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name  last_name                                   quote  \\\n",
       "0      Erika      Singh    \"Expanded upward-trending migration\"   \n",
       "1      David       Hill        \"Future-proofed coherent access\"   \n",
       "2   Brittany  Robertson  \"Networked fresh-thinking contingency\"   \n",
       "3   Victoria     Jacobs        \"Stand-alone maximized intranet\"   \n",
       "4  Christine  Davenport          \"Pre-emptive needs-based core\"   \n",
       "\n",
       "                            email                phone  \\\n",
       "0     heather10@sanford-tyler.com        (720)024-8715   \n",
       "1           beckmaureen@yahoo.com      +1-335-855-9267   \n",
       "2          curtisdennis@gmail.com  (278)228-4260x73351   \n",
       "3  smithrobert@reyes-gonzalez.org  +1-234-910-4214x821   \n",
       "4              tina36@hotmail.com   186-423-9531x65330   \n",
       "\n",
       "                                             address  \\\n",
       "0  86428 Carpenter Hills \\n                West A...   \n",
       "1  853 Barrett Passage \\n                Victoria...   \n",
       "2  396 Jennifer Trail \\n                West Mich...   \n",
       "3  2374 Nicole Ramp \\n                Jonathanfur...   \n",
       "4  3107 Brian Estates Suite 508 \\n               ...   \n",
       "\n",
       "                          street  \n",
       "0         86428 Carpenter Hills   \n",
       "1           853 Barrett Passage   \n",
       "2            396 Jennifer Trail   \n",
       "3              2374 Nicole Ramp   \n",
       "4  3107 Brian Estates Suite 508   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([parse_person(person) for person in people])\n",
    "df['street'] = df.address.str.extract(r'^(.+)\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbc4144",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e257c6",
   "metadata": {},
   "source": [
    "## 1. Codeup Blog Articles\n",
    "\n",
    "Visit Codeup's Blog and record the urls for at least 5 distinct blog posts. For each post, you should scrape at least the post's title and content.\n",
    "\n",
    "Encapsulate your work in a function named get_blog_articles that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba06a70",
   "metadata": {},
   "source": [
    "{\n",
    "    'title': 'the title of the article',\n",
    "    'content': 'the full text content of the article'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99467ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles(use_cache=True):\n",
    "    \n",
    "    # establish a filename for the local csv\n",
    "    filename = 'codeup_blog_articles.csv'\n",
    "    \n",
    "    if use_cache:\n",
    "        \n",
    "        # check to see if a local copy already exists\n",
    "        if os.path.exists(filename):\n",
    "            print('Reading from local CSV...')\n",
    "            # if so, return the local csv\n",
    "            return pd.read_csv(filename)\n",
    "        \n",
    "    # otherwise, scrape the data from codeup.com\n",
    "    print('Reading blog articles from codeup.com...')\n",
    "    \n",
    "    articles = []\n",
    "\n",
    "    # go to blog homepage\n",
    "    url = 'https://codeup.com/blog/'\n",
    "    headers = {'user-agent': 'Innis Data Science Cohort'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # get url for next page of articles\n",
    "    # (returns None if there are no more pages)\n",
    "    next_page = soup.select_one('.pagination.clearfix').div.a\n",
    "\n",
    "    # get the urls for the rest of the articles on this page\n",
    "    urls = []\n",
    "    for article in soup.select('article'):\n",
    "        #for link in article.select('.more-link'):\n",
    "        for link in article.select('.entry-featured-image-url'):\n",
    "            urls.append(link.attrs['href'])\n",
    "\n",
    "    # go to each article page\n",
    "    for url in urls:\n",
    "        response = get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # pull article info and append to list\n",
    "        dct = {}\n",
    "        dct['title'] = soup.select_one('.entry-title').text\n",
    "        dct['content'] = soup.select_one('.entry-content').text.strip()\n",
    "        articles.append(dct)\n",
    "\n",
    "    page_counter = 1\n",
    "    print(f'{page_counter} pages complete     ', end='\\r')\n",
    "\n",
    "    # check whether there is a next page\n",
    "    while next_page != None:\n",
    "        # go to the next page\n",
    "        url = next_page.attrs['href']\n",
    "        response = get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # get url for next page of articles\n",
    "        # (this will return None if there are no more pages)\n",
    "        next_page = soup.select_one('.pagination.clearfix').div.a\n",
    "\n",
    "        # get all the urls for articles on this page\n",
    "        urls = []\n",
    "        for article in soup.select('article'):\n",
    "            for link in article.select('.entry-featured-image-url'):\n",
    "                urls.append(link.attrs['href'])\n",
    "\n",
    "        # go to each article page\n",
    "        for url in urls:\n",
    "            response = get(url, headers=headers)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # pull article info and append to list\n",
    "            dct = {}\n",
    "            dct['title'] = soup.select_one('.entry-title').text\n",
    "            dct['content'] = soup.select_one('.entry-content').text.strip()\n",
    "            articles.append(dct)\n",
    "\n",
    "        page_counter += 1\n",
    "        print(f'{page_counter} pages complete     ', end='\\r')\n",
    "        \n",
    "    print(f'{page_counter} pages scraped. No more pages available.')\n",
    "    \n",
    "    articles = pd.DataFrame(articles)\n",
    "    \n",
    "    # cache local copy\n",
    "    print('Writing to local CSV...')\n",
    "    articles.to_csv(filename, index=False)\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7292dad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "df = acquire.get_blog_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b54c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From Bootcamp to Bootcamp | A Military Appreci...</td>\n",
       "      <td>In honor of Military Appreciation Month, join ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Acquisition of the Rackspace Cloud Academy...</td>\n",
       "      <td>Just about a year ago on April 16th, 2021 we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learn to Code: HTML &amp; CSS on 4/30</td>\n",
       "      <td>HTML &amp; CSS are the design building blocks of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learn to Code: Python Workshop on 4/23</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coming Soon: Cloud Administration</td>\n",
       "      <td>We’re launching a new program out of San Anton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>The College Financing Scam and How We’re Doing...</td>\n",
       "      <td>Here’s the dirty secret of private college “fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Why People Can’t Learn Programming on Their Own</td>\n",
       "      <td>While developing Codeup, we interviewed dozens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>What is Our Noble Cause?</td>\n",
       "      <td>In his TEDx San Antonio presentation this fall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Scholarships for Women: Why We’re Doing It</td>\n",
       "      <td>A hot topic that is trending is the special tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Student Profile: Leslie Tolbert</td>\n",
       "      <td>Leslie Tolbert, Texas State graduate and commu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    From Bootcamp to Bootcamp | A Military Appreci...   \n",
       "1    Our Acquisition of the Rackspace Cloud Academy...   \n",
       "2                    Learn to Code: HTML & CSS on 4/30   \n",
       "3               Learn to Code: Python Workshop on 4/23   \n",
       "4                    Coming Soon: Cloud Administration   \n",
       "..                                                 ...   \n",
       "193  The College Financing Scam and How We’re Doing...   \n",
       "194    Why People Can’t Learn Programming on Their Own   \n",
       "195                           What is Our Noble Cause?   \n",
       "196         Scholarships for Women: Why We’re Doing It   \n",
       "197                    Student Profile: Leslie Tolbert   \n",
       "\n",
       "                                               content  \n",
       "0    In honor of Military Appreciation Month, join ...  \n",
       "1    Just about a year ago on April 16th, 2021 we a...  \n",
       "2    HTML & CSS are the design building blocks of a...  \n",
       "3    According to LinkedIn, the “#1 Most Promising ...  \n",
       "4    We’re launching a new program out of San Anton...  \n",
       "..                                                 ...  \n",
       "193  Here’s the dirty secret of private college “fi...  \n",
       "194  While developing Codeup, we interviewed dozens...  \n",
       "195  In his TEDx San Antonio presentation this fall...  \n",
       "196  A hot topic that is trending is the special tr...  \n",
       "197  Leslie Tolbert, Texas State graduate and commu...  \n",
       "\n",
       "[198 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee891a27",
   "metadata": {},
   "source": [
    "# 2. News Articles\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "    Business\n",
    "    Sports\n",
    "    Technology\n",
    "    Entertainment\n",
    "\n",
    "The end product of this should be a function named get_news_articles that returns a list of dictionaries, where each dictionary has this shape:\n",
    "\n",
    "{\n",
    "    'title': 'The article title',\n",
    "    'content': 'The article content',\n",
    "    'category': 'business' # for example\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1b9d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://inshorts.com/en/read'\n",
    "response = get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f45d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "dct = {}\n",
    "dct['title'] = soup.select('.news-card')[0].select('.news-card-title')[0].span.text\n",
    "dct['content'] = soup.select('.news-card')[0].select('.news-card-content')[0].div.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504c639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles(categories=['business', 'sports', \n",
    "                                  'technology', 'entertainment'], \n",
    "                      use_cache=True):\n",
    "    \n",
    "    # establish a filename for the local csv\n",
    "    filename = 'news_articles.csv'\n",
    "    \n",
    "    if use_cache:\n",
    "        # check to see if a local copy already exists\n",
    "        if os.path.exists(filename):\n",
    "            print('Reading from local CSV...')\n",
    "            # if so, return the local csv\n",
    "            return pd.read_csv(filename)\n",
    "        \n",
    "    # otherwise, scrape the data from codeup.com\n",
    "    print('Reading blog articles from inshorts.com...')\n",
    "\n",
    "    articles = []\n",
    "\n",
    "    for category in categories:\n",
    "\n",
    "        url = f'https://inshorts.com/en/read/{category}'\n",
    "        response = get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for card in soup.select('.news-card'):\n",
    "            dct = {}\n",
    "            dct['title'] = card.select('.news-card-title')[0].span.text\n",
    "            dct['author'] = card.select('.author')[0].text\n",
    "            dct['content'] = card.select_one('.news-card-content').div.text\n",
    "            dct['category'] = category\n",
    "            articles.append(dct)\n",
    "            \n",
    "    articles = pd.DataFrame(articles)\n",
    "    \n",
    "    # cache local copy\n",
    "    print('Writing to local CSV...')\n",
    "    articles.to_csv(filename, index=False)\n",
    "            \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d2d634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupee hits all-time low of 77.42 against US do...</td>\n",
       "      <td>Apaar Sharma</td>\n",
       "      <td>The Indian rupee fell to an all-time low of 77...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin falls to the lowest level since Januar...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>Bitcoin fell on Monday to as low as $33,266 in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Made best possible decision: IndiGo on barring...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>IndiGo's CEO Ronojoy Dutta said the airline ma...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India's biggest IPO of LIC subscribed nearly 3...</td>\n",
       "      <td>Pragya Swastik</td>\n",
       "      <td>LIC's IPO, India's biggest IPO which opened on...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If I die under mysterious circumstances, nice ...</td>\n",
       "      <td>Ridham Gambhir</td>\n",
       "      <td>Tesla CEO Elon Musk has tweeted, \"If I die und...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>He's done right thing: Neetu on Ranbir not bei...</td>\n",
       "      <td>Kriti Kambiri</td>\n",
       "      <td>Actress Neetu Kapoor has said that her son Ran...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fred Savage fired from Wonder Years after alle...</td>\n",
       "      <td>Udit Gupta</td>\n",
       "      <td>Fred Savage has been dropped from the comedy s...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Comedy is the nicest genre; it's difficult to ...</td>\n",
       "      <td>Mahima Kharbanda</td>\n",
       "      <td>Actress Samantha Prabhu said that she wants to...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>People taunted me for not getting pregnant, tr...</td>\n",
       "      <td>Kriti Kambiri</td>\n",
       "      <td>Actress Sambhavna Seth has revealed that she h...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Kids don't care: Kunal on Taimur being trolled...</td>\n",
       "      <td>Kriti Kambiri</td>\n",
       "      <td>Actor Kunal Kemmu has reacted to Saif Ali Khan...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title            author  \\\n",
       "0   Rupee hits all-time low of 77.42 against US do...      Apaar Sharma   \n",
       "1   Bitcoin falls to the lowest level since Januar...    Pragya Swastik   \n",
       "2   Made best possible decision: IndiGo on barring...    Pragya Swastik   \n",
       "3   India's biggest IPO of LIC subscribed nearly 3...    Pragya Swastik   \n",
       "4   If I die under mysterious circumstances, nice ...    Ridham Gambhir   \n",
       "..                                                ...               ...   \n",
       "94  He's done right thing: Neetu on Ranbir not bei...     Kriti Kambiri   \n",
       "95  Fred Savage fired from Wonder Years after alle...        Udit Gupta   \n",
       "96  Comedy is the nicest genre; it's difficult to ...  Mahima Kharbanda   \n",
       "97  People taunted me for not getting pregnant, tr...     Kriti Kambiri   \n",
       "98  Kids don't care: Kunal on Taimur being trolled...     Kriti Kambiri   \n",
       "\n",
       "                                              content       category  \n",
       "0   The Indian rupee fell to an all-time low of 77...       business  \n",
       "1   Bitcoin fell on Monday to as low as $33,266 in...       business  \n",
       "2   IndiGo's CEO Ronojoy Dutta said the airline ma...       business  \n",
       "3   LIC's IPO, India's biggest IPO which opened on...       business  \n",
       "4   Tesla CEO Elon Musk has tweeted, \"If I die und...       business  \n",
       "..                                                ...            ...  \n",
       "94  Actress Neetu Kapoor has said that her son Ran...  entertainment  \n",
       "95  Fred Savage has been dropped from the comedy s...  entertainment  \n",
       "96  Actress Samantha Prabhu said that she wants to...  entertainment  \n",
       "97  Actress Sambhavna Seth has revealed that she h...  entertainment  \n",
       "98  Actor Kunal Kemmu has reacted to Saif Ali Khan...  entertainment  \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_news_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb14c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
