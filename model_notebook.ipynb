{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9420d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import env\n",
    "\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42d04bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "id                                                         \n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = env.get_db_url('spam_db')\n",
    "sql = 'SELECT * FROM spam'\n",
    "df = pd.read_sql(sql, url, index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d20fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'text': 'content'})\n",
    "df = prepare.nlp_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df348c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           original  \\\n",
       "id                                                            \n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "\n",
       "                                                clean  \\\n",
       "id                                                      \n",
       "0   go jurong point crazy available bugis n great ...   \n",
       "1                             ok lar joking wif u oni   \n",
       "2   free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "id                                                      \n",
       "0   go jurong point crazi avail bugi n great world...   \n",
       "1                               ok lar joke wif u oni   \n",
       "2   free entri 2 wkli comp win fa cup final tkt 21...   \n",
       "\n",
       "                                           lemmatized  \n",
       "id                                                     \n",
       "0   go jurong point crazy available bugis n great ...  \n",
       "1                             ok lar joking wif u oni  \n",
       "2   free entry 2 wkly comp win fa cup final tkts 2...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfa61e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2836b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word, corpus):\n",
    "    n_docs = len(corpus)\n",
    "    n_docs_with_word = sum([1 for doc in corpus if word in doc])\n",
    "    idf = log(n_docs / n_docs_with_word)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb610fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6133940405933165"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('go', df.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c67b248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_words = pd.Series(' '.join(df.lemmatized).split()).unique()\n",
    "# words_df = pd.DataFrame(dict(word=unique_words))\n",
    "# words_df['idf'] = words_df.word.apply(lambda word: idf(word, df.lemmatized))\n",
    "# words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b75e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words_df = pd.DataFrame()\n",
    "\n",
    "# counter = 1\n",
    "# for doc in df.lemmatized:\n",
    "#     for word in doc.split():\n",
    "#         dct = {}\n",
    "#         dct['word'] = word\n",
    "#         dct['doc'] = doc\n",
    "#         dct['tf'] = doc.split().count(word)\n",
    "#         dct['idf'] = idf(word, df.lemmatized)\n",
    "#         dct['tf_idf'] = dct['tf'] * dct['idf']\n",
    "    \n",
    "#         words_df = words_df.append(dct, ignore_index=True)\n",
    "        \n",
    "#     print(f'{counter}/{len(df.lemmatized)}, {round(counter/len(df.lemmatized)*100)}% complete\\t\\t', \n",
    "#           end='\\r')\n",
    "#     counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520d23e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zb/3lg9b5xn3831bhkh23bd5bs00000gn/T/ipykernel_26244/1697954886.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'words_df' is not defined"
     ]
    }
   ],
   "source": [
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = pd.DataFrame()\n",
    "counter = 1\n",
    "for doc in df.lemmatized:\n",
    "    dct = {}\n",
    "    dct['doc'] = doc\n",
    "    for word in doc.split():\n",
    "        tf = doc.count(word)\n",
    "        idf = idf(word, df.lemmatized)\n",
    "        dct[f'{word}_tfidf'] = tf * idf\n",
    "        docs_df.append(dct, ignore_index=True)\n",
    "    print(f'{counter/len(df.lemmatized)*100}% complete')\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26108919",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf(word, df.lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ea487",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47609079",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06912754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
